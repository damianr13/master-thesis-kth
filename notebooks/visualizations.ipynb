{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.predictors.contrastive import ContrastivePretrainModel, ContrastiveClassifierConfig\n",
    "from src.utils import load_as_object\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[COL] title [VAL] corsair cmu32gx4m4c3000c15 [...</td>\n",
       "      <td>279422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[COL] title [VAL] gigabyte gb bxbt 3000 brix p...</td>\n",
       "      <td>277774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[COL] title [VAL] seagate laptop sshd hybrid 2...</td>\n",
       "      <td>423211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[COL] title [VAL] buy online zotac gtx 1060 6g...</td>\n",
       "      <td>824793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[COL] title [VAL] apple 13 3 inch macbook pro ...</td>\n",
       "      <td>5114428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[COL] title [VAL] gigabyte radeon rx 580 gamin...</td>\n",
       "      <td>1324529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[COL] title [VAL] lenovo thinkpad work in case...</td>\n",
       "      <td>10641662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[COL] title [VAL] hp workstation z440 mt xeon ...</td>\n",
       "      <td>1464484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[COL] title [VAL] apple ipad pro 12 9 retina d...</td>\n",
       "      <td>1025712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[COL] title [VAL] intel core i5 4590 3 ghz pro...</td>\n",
       "      <td>129361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cluster_id\n",
       "0  [COL] title [VAL] corsair cmu32gx4m4c3000c15 [...      279422\n",
       "1  [COL] title [VAL] gigabyte gb bxbt 3000 brix p...      277774\n",
       "2  [COL] title [VAL] seagate laptop sshd hybrid 2...      423211\n",
       "3  [COL] title [VAL] buy online zotac gtx 1060 6g...      824793\n",
       "4  [COL] title [VAL] apple 13 3 inch macbook pro ...     5114428\n",
       "5  [COL] title [VAL] gigabyte radeon rx 580 gamin...     1324529\n",
       "6  [COL] title [VAL] lenovo thinkpad work in case...    10641662\n",
       "7  [COL] title [VAL] hp workstation z440 mt xeon ...     1464484\n",
       "8  [COL] title [VAL] apple ipad pro 12 9 retina d...     1025712\n",
       "9  [COL] title [VAL] intel core i5 4590 3 ghz pro...      129361"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[COL] title [VAL] null , 238590 b21 hp 36 4 gb...</td>\n",
       "      <td>10952886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[COL] title [VAL] router wi fi ac750 cloud dir...</td>\n",
       "      <td>903353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[COL] title [VAL] micron 1100 solid state driv...</td>\n",
       "      <td>570789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[COL] title [VAL] 495605 b21 hp 64 gb 8x8gb pc...</td>\n",
       "      <td>13412888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[COL] title [VAL] msi amd am4 ryzen b350 tomah...</td>\n",
       "      <td>9092077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[COL] title [VAL] null , 643772 b21 hp xeon e7...</td>\n",
       "      <td>119752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[COL] title [VAL] hp pl 8500r 2 xeon 550mhz 1m...</td>\n",
       "      <td>10713540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[COL] title [VAL] corsair vengeance led 16gb 2...</td>\n",
       "      <td>1044577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[COL] title [VAL] wd 120gb green sata 6gb s 2 ...</td>\n",
       "      <td>809618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[COL] title [VAL] startech displayport to hdmi...</td>\n",
       "      <td>1219171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cluster_id\n",
       "0  [COL] title [VAL] null , 238590 b21 hp 36 4 gb...    10952886\n",
       "1  [COL] title [VAL] router wi fi ac750 cloud dir...      903353\n",
       "2  [COL] title [VAL] micron 1100 solid state driv...      570789\n",
       "3  [COL] title [VAL] 495605 b21 hp 64 gb 8x8gb pc...    13412888\n",
       "4  [COL] title [VAL] msi amd am4 ryzen b350 tomah...     9092077\n",
       "5  [COL] title [VAL] null , 643772 b21 hp xeon e7...      119752\n",
       "6  [COL] title [VAL] hp pl 8500r 2 xeon 550mhz 1m...    10713540\n",
       "7  [COL] title [VAL] corsair vengeance led 16gb 2...     1044577\n",
       "8  [COL] title [VAL] wd 120gb green sata 6gb s 2 ...      809618\n",
       "9  [COL] title [VAL] startech displayport to hdmi...     1219171"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_offers_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/pretrain-train.csv')\n",
    "train_offers_df.head(10)\n",
    "\n",
    "valid_offers_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/pretrain-valid.csv')\n",
    "valid_offers_df.head(10)\n",
    "\n",
    "train_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/train.csv')\n",
    "valid_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/valid.csv')\n",
    "test_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer(test_offers_df['text'].iloc[0]).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def encode_offer(value: str, tokenizer, bert, config) -> List[int]:\n",
    "    tokens = tokenizer(value, return_tensors=\"pt\", max_length=config.max_tokens, truncation=True)\n",
    "    encoding = bert(tokens['input_ids'], attention_mask=tokens['attention_mask'])\n",
    "    return encoding.last_hidden_state[0][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     test_offers_df['embedding'] = test_offers_df['text'].apply(encode_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     result = encode_offer(test_offers_df['text'].iloc[0])\n",
    "#     print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed numpy version 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'Installed numpy version {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def project2d(target: pd.DataFrame, tokenizer, model: ContrastivePretrainModel, config: ContrastiveClassifierConfig) -> pd.DataFrame:\n",
    "    df = target.copy()\n",
    "    with torch.no_grad():\n",
    "        df['embedding'] = df['text'].apply(lambda v: encode_offer(v, tokenizer, model.transformer, config))\n",
    "\n",
    "    embeddings_list = df['embedding'].tolist()\n",
    "    embeddings = np.asarray(embeddings_list, dtype='float')\n",
    "    scaler =  MinMaxScaler()\n",
    "    features = scaler.fit_transform(embeddings)\n",
    "    mapper = umap.UMAP(n_components=2, metric=\"cosine\", random_state=42).fit(features) # TODO: fit once use it for all the epochs\n",
    "\n",
    "    projection_df = pd.DataFrame(mapper.embedding_, columns=['X', 'Y'])\n",
    "    projection_df['X'] = scaler.fit_transform(projection_df[['X']])\n",
    "    projection_df['Y'] = scaler.fit_transform(projection_df[['Y']])\n",
    "    projection_df['label'] = df['cluster_id']\n",
    "    return projection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mplcursors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "from distinctipy import distinctipy\n",
    "\n",
    "train_offers_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/pretrain-train.csv')\n",
    "df_emb = train_offers_df.copy()\n",
    "color_palette = distinctipy.get_colors(20)\n",
    "\n",
    "df_labels = df_emb[['cluster_id']].drop_duplicates()\n",
    "# color_repeat_count = len(df_labels) // len(color_palette) + 1\n",
    "# color_palette = color_palette * color_repeat_count\n",
    "# color_palette = color_palette[:len(df_labels)]\n",
    "df_labels = df_labels.sample(n=20)\n",
    "df_labels['color'] = color_palette\n",
    "\n",
    "df_sampled_emb = df_emb.join(df_labels.set_index('cluster_id'), on='cluster_id', rsuffix='_c', how=\"right\")\n",
    "df_sampled_emb = df_sampled_emb.reset_index()\n",
    "print(len(df_sampled_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/vocab.txt from cache at /home/robert/.cache/huggingface/transformers/4ec675a1f3cd38f2ddbe71010ce58471a710dd0188687381cf6f06fa7860c86a.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Adding [COL] to the vocabulary\n",
      "Adding [VAL] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3r5jcj7l:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3r5jcj7l:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-97ju0sgh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-97ju0sgh:v0/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/sampled/frozen_no-aug_batch-pt128_sample50_wdc-computers-medium.json')\n",
    "predictor.config.unfreeze = False\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "checkpoint_model = ContrastivePretrainModel(transformer=predictor.trainer.model.transformer)\n",
    "# cursor = mplcursors.cursor(sc, hover=True)\n",
    "# cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "# checkpoint_path = checkpoint.split('/')\n",
    "# plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "# print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import seed_all\n",
    "seed_all(42)\n",
    "\n",
    "df_emb = project2d(df_sampled_emb, tokenizer=predictor.tokenizer, model=checkpoint_model, config=predictor.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "#\n",
    "# checkpoints = glob.glob(\"output/contrastive_frozen_wdc-computers-medium/pretrain/checkpoint-[0-9]*\")\n",
    "# checkpoints = sorted(checkpoints, key=lambda x: int(x.split('/')[-1].split('-')[-1]))\n",
    "#\n",
    "# config: ContrastiveClassifierConfig = load_as_object(\n",
    "#     \"configs/model_train/contrastive/frozen_no-aug_wdc-computers-medium.json\",\n",
    "#     ContrastiveClassifierConfig.parse_obj)\n",
    "# pretrained_tokenizer = AutoTokenizer.from_pretrained(config.transformer_name,\n",
    "#                                                      additional_special_tokens=('[COL]', '[VAL]'))\n",
    "#\n",
    "# figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "# if not os.path.exists(figures_dir):\n",
    "#     os.makedirs(figures_dir)\n",
    "#\n",
    "# for checkpoint in checkpoints:\n",
    "#     checkpoint_model = ContrastivePretrainModel(len_tokenizer=len(pretrained_tokenizer), model=config.transformer_name)\n",
    "#\n",
    "#     model_state = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))\n",
    "#     checkpoint_model.load_state_dict(model_state)\n",
    "#     checkpoint_model.to(torch.device('cpu'))\n",
    "#\n",
    "#\n",
    "#     df_emb = project2d(df_sampled_emb, tokenizer=pretrained_tokenizer, model=checkpoint_model)\n",
    "#     df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "#     df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "#\n",
    "#     fig, ax = plt.subplots()\n",
    "#     sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])\n",
    "#     # cursor = mplcursors.cursor(sc, hover=True)\n",
    "#     # cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "#     checkpoint_path = checkpoint.split('/')\n",
    "#     plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "#     print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "frame_paths = glob.glob(os.path.join(figures_dir, '*.png'))\n",
    "frame_paths = sorted(frame_paths, key=lambda x: int(x.split('/')[-1].split('.')[0].split('-')[-1]))\n",
    "\n",
    "frames = [Image.open(i) for i in frame_paths]\n",
    "frames[0].save(os.path.join(figures_dir, 'all.gif'), format='GIF', append_images=frames[1:], save_all=True, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3rfzmkeh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3rfzmkeh:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-wm5888ah:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-wm5888ah:v0/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985507246376812, 0.9765100671140939\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "unfrozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/unfrozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "frozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/frozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "# unfrozen_predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "unfrozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "frozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "unfrozen_f1 = unfrozen_predictor.test(test_df)\n",
    "frozen_f1 = frozen_predictor.test(test_df)\n",
    "\n",
    "print(f\"{unfrozen_f1}, {frozen_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.predictors.contrastive import ContrastivePretrainModel, ContrastiveClassifierConfig\n",
    "from src.utils import load_as_object\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  cluster_id source\n0  [COL] name [VAL] Football card Gift bag FIFA 3...         495     #1\n1  [COL] name [VAL] Ear hook for earring 100 pcs ...         172     #1\n2  [COL] name [VAL] Borate, Mankini - Neon Green ...         144     #1\n3                [COL] name [VAL] Beach set, 9-parts         136     #1\n4  [COL] name [VAL] Diamond painting, diamantmåln...         164     #1\n5  [COL] name [VAL] Soccer Card - Pocket Tin / Gi...         576     #1\n6  [COL] name [VAL] 20pcs Rubber Bear Candy Resin...          55     #1\n7  [COL] name [VAL] Batman - cape / mantle / mask...         449     #1\n8  [COL] name [VAL] Battery cover and seal for Xi...         450     #1\n9  [COL] name [VAL] Pickguard case with keychain ...         553     #1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>cluster_id</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[COL] name [VAL] Football card Gift bag FIFA 3...</td>\n      <td>495</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COL] name [VAL] Ear hook for earring 100 pcs ...</td>\n      <td>172</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[COL] name [VAL] Borate, Mankini - Neon Green ...</td>\n      <td>144</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[COL] name [VAL] Beach set, 9-parts</td>\n      <td>136</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[COL] name [VAL] Diamond painting, diamantmåln...</td>\n      <td>164</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[COL] name [VAL] Soccer Card - Pocket Tin / Gi...</td>\n      <td>576</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[COL] name [VAL] 20pcs Rubber Bear Candy Resin...</td>\n      <td>55</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[COL] name [VAL] Batman - cape / mantle / mask...</td>\n      <td>449</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[COL] name [VAL] Battery cover and seal for Xi...</td>\n      <td>450</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[COL] name [VAL] Pickguard case with keychain ...</td>\n      <td>553</td>\n      <td>#1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "                                                text  cluster_id source\n0  [COL] name [VAL] Bathroom 360 Rotation Shower ...         135     #1\n1  [COL] name [VAL] Samsung Galaxy A12 - Pop It F...         280     #1\n2               [COL] name [VAL] Hand and footprints         505     #1\n3          [COL] name [VAL] Magnetic Tiles, 40 parts         230     #1\n4  [COL] name [VAL] Storage box for jewelery maki...         312     #1\n5  [COL] name [VAL] 2-Pack - Tangle Twist Fidget ...          40     #1\n6  [COL] name [VAL] Collapsible water tank Hiking...         151     #1\n7             [COL] name [VAL] Nanotape Reusable 3 m         241     #1\n8  [COL] name [VAL] 48 pcs Pokémon Figures | Coll...          82     #1\n9  [COL] name [VAL] Football card Starter package...         497     #1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>cluster_id</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[COL] name [VAL] Bathroom 360 Rotation Shower ...</td>\n      <td>135</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COL] name [VAL] Samsung Galaxy A12 - Pop It F...</td>\n      <td>280</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[COL] name [VAL] Hand and footprints</td>\n      <td>505</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[COL] name [VAL] Magnetic Tiles, 40 parts</td>\n      <td>230</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[COL] name [VAL] Storage box for jewelery maki...</td>\n      <td>312</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[COL] name [VAL] 2-Pack - Tangle Twist Fidget ...</td>\n      <td>40</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[COL] name [VAL] Collapsible water tank Hiking...</td>\n      <td>151</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[COL] name [VAL] Nanotape Reusable 3 m</td>\n      <td>241</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[COL] name [VAL] 48 pcs Pokémon Figures | Coll...</td>\n      <td>82</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[COL] name [VAL] Football card Starter package...</td>\n      <td>497</td>\n      <td>#1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'proprietary_scarce'\n",
    "\n",
    "train_offers_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/pretrain-train.csv')\n",
    "train_offers_df.head(10)\n",
    "\n",
    "valid_offers_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/pretrain-valid.csv')\n",
    "valid_offers_df.head(10)\n",
    "\n",
    "train_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/train.csv')\n",
    "valid_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/valid.csv')\n",
    "test_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer(test_offers_df['text'].iloc[0]).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def encode_offer(value: str, tokenizer, bert, config) -> List[int]:\n",
    "    tokens = tokenizer(value, return_tensors=\"pt\", max_length=config.max_tokens, truncation=True)\n",
    "    encoding = bert(tokens['input_ids'], attention_mask=tokens['attention_mask'])\n",
    "    return encoding.last_hidden_state[0][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     test_offers_df['embedding'] = test_offers_df['text'].apply(encode_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     result = encode_offer(test_offers_df['text'].iloc[0])\n",
    "#     print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed numpy version 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'Installed numpy version {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def project2d(target: pd.DataFrame, tokenizer, model: ContrastivePretrainModel, config: ContrastiveClassifierConfig) -> pd.DataFrame:\n",
    "    df = target.copy()\n",
    "    with torch.no_grad():\n",
    "        df['embedding'] = df['text'].apply(lambda v: encode_offer(v, tokenizer, model.transformer, config))\n",
    "\n",
    "    embeddings_list = df['embedding'].tolist()\n",
    "    embeddings = np.asarray(embeddings_list, dtype='float')\n",
    "    scaler =  MinMaxScaler()\n",
    "    features = scaler.fit_transform(embeddings)\n",
    "    mapper = umap.UMAP(n_components=2, metric=\"cosine\", random_state=42).fit(features) # TODO: fit once use it for all the epochs\n",
    "\n",
    "    projection_df = pd.DataFrame(mapper.embedding_, columns=['X', 'Y'])\n",
    "    projection_df['X'] = scaler.fit_transform(projection_df[['X']])\n",
    "    projection_df['Y'] = scaler.fit_transform(projection_df[['Y']])\n",
    "    projection_df['label'] = df['cluster_id']\n",
    "    return projection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mplcursors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "from distinctipy import distinctipy\n",
    "\n",
    "train_offers_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/pretrain-valid.csv')\n",
    "df_emb = train_offers_df.copy()\n",
    "color_palette = distinctipy.get_colors(20)\n",
    "\n",
    "df_labels = df_emb[['cluster_id']].drop_duplicates()\n",
    "# color_repeat_count = len(df_labels) // len(color_palette) + 1\n",
    "# color_palette = color_palette * color_repeat_count\n",
    "# color_palette = color_palette[:len(df_labels)]\n",
    "df_labels = df_labels.sample(n=20)\n",
    "df_labels['color'] = color_palette\n",
    "\n",
    "df_sampled_emb = df_emb.join(df_labels.set_index('cluster_id'), on='cluster_id', rsuffix='_c', how=\"right\")\n",
    "df_sampled_emb = df_sampled_emb.reset_index()\n",
    "print(len(df_sampled_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.0.bias', 'fit_denses.2.bias', 'cls.predictions.decoder.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'cls.predictions.transform.LayerNorm.bias', 'fit_denses.3.bias', 'fit_denses.4.weight', 'fit_denses.2.weight', 'cls.seq_relationship.bias', 'fit_denses.1.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'fit_denses.3.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-3r5jcj7l:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3r5jcj7l:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-97ju0sgh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.0.bias', 'fit_denses.2.bias', 'cls.predictions.decoder.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'cls.predictions.transform.LayerNorm.bias', 'fit_denses.3.bias', 'fit_denses.4.weight', 'fit_denses.2.weight', 'cls.seq_relationship.bias', 'fit_denses.1.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'fit_denses.3.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-97ju0sgh:v0/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/sampled/frozen_no-aug_batch-pt128_sample50_wdc-computers-medium.json')\n",
    "predictor.config.unfreeze = False\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "checkpoint_model = ContrastivePretrainModel(transformer=predictor.trainer.model.transformer)\n",
    "# cursor = mplcursors.cursor(sc, hover=True)\n",
    "# cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "# checkpoint_path = checkpoint.split('/')\n",
    "# plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "# print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import seed_all\n",
    "seed_all(42)\n",
    "\n",
    "df_emb = project2d(df_sampled_emb, tokenizer=predictor.tokenizer, model=checkpoint_model, config=predictor.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "#\n",
    "# checkpoints = glob.glob(\"output/contrastive_frozen_wdc-computers-medium/pretrain/checkpoint-[0-9]*\")\n",
    "# checkpoints = sorted(checkpoints, key=lambda x: int(x.split('/')[-1].split('-')[-1]))\n",
    "#\n",
    "# config: ContrastiveClassifierConfig = load_as_object(\n",
    "#     \"configs/model_train/contrastive/frozen_no-aug_wdc-computers-medium.json\",\n",
    "#     ContrastiveClassifierConfig.parse_obj)\n",
    "# pretrained_tokenizer = AutoTokenizer.from_pretrained(config.transformer_name,\n",
    "#                                                      additional_special_tokens=('[COL]', '[VAL]'))\n",
    "#\n",
    "# figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "# if not os.path.exists(figures_dir):\n",
    "#     os.makedirs(figures_dir)\n",
    "#\n",
    "# for checkpoint in checkpoints:\n",
    "#     checkpoint_model = ContrastivePretrainModel(len_tokenizer=len(pretrained_tokenizer), model=config.transformer_name)\n",
    "#\n",
    "#     model_state = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))\n",
    "#     checkpoint_model.load_state_dict(model_state)\n",
    "#     checkpoint_model.to(torch.device('cpu'))\n",
    "#\n",
    "#\n",
    "#     df_emb = project2d(df_sampled_emb, tokenizer=pretrained_tokenizer, model=checkpoint_model)\n",
    "#     df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "#     df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "#\n",
    "#     fig, ax = plt.subplots()\n",
    "#     sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])\n",
    "#     # cursor = mplcursors.cursor(sc, hover=True)\n",
    "#     # cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "#     checkpoint_path = checkpoint.split('/')\n",
    "#     plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "#     print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "frame_paths = glob.glob(os.path.join(figures_dir, '*.png'))\n",
    "frame_paths = sorted(frame_paths, key=lambda x: int(x.split('/')[-1].split('.')[0].split('-')[-1]))\n",
    "\n",
    "frames = [Image.open(i) for i in frame_paths]\n",
    "frames[0].save(os.path.join(figures_dir, 'all.gif'), format='GIF', append_images=frames[1:], save_all=True, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-3rfzmkeh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3rfzmkeh:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-wm5888ah:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-wm5888ah:v0/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985507246376812, 0.9765100671140939\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "unfrozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/unfrozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "frozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/frozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "# unfrozen_predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "unfrozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "frozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "unfrozen_f1 = unfrozen_predictor.test(test_df)\n",
    "frozen_f1 = frozen_predictor.test(test_df)\n",
    "\n",
    "print(f\"{unfrozen_f1}, {frozen_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
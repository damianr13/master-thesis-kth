{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.predictors.contrastive import ContrastivePretrainModel, ContrastiveClassifierConfig\n",
    "from src.utils import load_as_object\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  cluster_id source\n0  [COL] name [VAL] Football card Gift bag FIFA 3...         495     #1\n1  [COL] name [VAL] Ear hook for earring 100 pcs ...         172     #1\n2  [COL] name [VAL] Borate, Mankini - Neon Green ...         144     #1\n3                [COL] name [VAL] Beach set, 9-parts         136     #1\n4  [COL] name [VAL] Diamond painting, diamantmåln...         164     #1\n5  [COL] name [VAL] Soccer Card - Pocket Tin / Gi...         576     #1\n6  [COL] name [VAL] 20pcs Rubber Bear Candy Resin...          55     #1\n7  [COL] name [VAL] Batman - cape / mantle / mask...         449     #1\n8  [COL] name [VAL] Battery cover and seal for Xi...         450     #1\n9  [COL] name [VAL] Pickguard case with keychain ...         553     #1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>cluster_id</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[COL] name [VAL] Football card Gift bag FIFA 3...</td>\n      <td>495</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COL] name [VAL] Ear hook for earring 100 pcs ...</td>\n      <td>172</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[COL] name [VAL] Borate, Mankini - Neon Green ...</td>\n      <td>144</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[COL] name [VAL] Beach set, 9-parts</td>\n      <td>136</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[COL] name [VAL] Diamond painting, diamantmåln...</td>\n      <td>164</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[COL] name [VAL] Soccer Card - Pocket Tin / Gi...</td>\n      <td>576</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[COL] name [VAL] 20pcs Rubber Bear Candy Resin...</td>\n      <td>55</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[COL] name [VAL] Batman - cape / mantle / mask...</td>\n      <td>449</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[COL] name [VAL] Battery cover and seal for Xi...</td>\n      <td>450</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[COL] name [VAL] Pickguard case with keychain ...</td>\n      <td>553</td>\n      <td>#1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "                                                text  cluster_id source\n0  [COL] name [VAL] Bathroom 360 Rotation Shower ...         135     #1\n1  [COL] name [VAL] Samsung Galaxy A12 - Pop It F...         280     #1\n2               [COL] name [VAL] Hand and footprints         505     #1\n3          [COL] name [VAL] Magnetic Tiles, 40 parts         230     #1\n4  [COL] name [VAL] Storage box for jewelery maki...         312     #1\n5  [COL] name [VAL] 2-Pack - Tangle Twist Fidget ...          40     #1\n6  [COL] name [VAL] Collapsible water tank Hiking...         151     #1\n7             [COL] name [VAL] Nanotape Reusable 3 m         241     #1\n8  [COL] name [VAL] 48 pcs Pokémon Figures | Coll...          82     #1\n9  [COL] name [VAL] Football card Starter package...         497     #1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>cluster_id</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[COL] name [VAL] Bathroom 360 Rotation Shower ...</td>\n      <td>135</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COL] name [VAL] Samsung Galaxy A12 - Pop It F...</td>\n      <td>280</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[COL] name [VAL] Hand and footprints</td>\n      <td>505</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[COL] name [VAL] Magnetic Tiles, 40 parts</td>\n      <td>230</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[COL] name [VAL] Storage box for jewelery maki...</td>\n      <td>312</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[COL] name [VAL] 2-Pack - Tangle Twist Fidget ...</td>\n      <td>40</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[COL] name [VAL] Collapsible water tank Hiking...</td>\n      <td>151</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[COL] name [VAL] Nanotape Reusable 3 m</td>\n      <td>241</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[COL] name [VAL] 48 pcs Pokémon Figures | Coll...</td>\n      <td>82</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[COL] name [VAL] Football card Starter package...</td>\n      <td>497</td>\n      <td>#1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'proprietary_scarce'\n",
    "\n",
    "train_offers_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/pretrain-train.csv')\n",
    "train_offers_df.head(10)\n",
    "\n",
    "valid_offers_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/pretrain-valid.csv')\n",
    "valid_offers_df.head(10)\n",
    "\n",
    "train_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/train.csv')\n",
    "valid_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/valid.csv')\n",
    "test_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer(test_offers_df['text'].iloc[0]).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def encode_offer(value: str, tokenizer, bert, config) -> List[int]:\n",
    "    tokens = tokenizer(value, return_tensors=\"pt\", max_length=config.max_tokens, truncation=True)\n",
    "    encoding = bert(tokens['input_ids'], attention_mask=tokens['attention_mask'])\n",
    "    return encoding.last_hidden_state[0][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     test_offers_df['embedding'] = test_offers_df['text'].apply(encode_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     result = encode_offer(test_offers_df['text'].iloc[0])\n",
    "#     print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed numpy version 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'Installed numpy version {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def project2d(target: pd.DataFrame, tokenizer, model: ContrastivePretrainModel, config: ContrastiveClassifierConfig) -> pd.DataFrame:\n",
    "    df = target.copy()\n",
    "    with torch.no_grad():\n",
    "        df['embedding'] = df['text'].apply(lambda v: encode_offer(v, tokenizer, model.transformer, config))\n",
    "\n",
    "    embeddings_list = df['embedding'].tolist()\n",
    "    embeddings = np.asarray(embeddings_list, dtype='float')\n",
    "    scaler =  MinMaxScaler()\n",
    "    features = scaler.fit_transform(embeddings)\n",
    "    mapper = umap.UMAP(n_components=2, metric=\"cosine\", random_state=42).fit(features) # TODO: fit once use it for all the epochs\n",
    "\n",
    "    projection_df = pd.DataFrame(mapper.embedding_, columns=['X', 'Y'])\n",
    "    projection_df['X'] = scaler.fit_transform(projection_df[['X']])\n",
    "    projection_df['Y'] = scaler.fit_transform(projection_df[['Y']])\n",
    "    projection_df['label'] = df['cluster_id']\n",
    "    return projection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mplcursors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "from distinctipy import distinctipy\n",
    "\n",
    "train_offers_df = pd.read_csv('data/processed/contrastive/wdc_computers_medium/pretrain-train.csv')\n",
    "df_emb = train_offers_df.copy()\n",
    "color_palette = distinctipy.get_colors(20)\n",
    "\n",
    "df_labels = df_emb[['cluster_id']].drop_duplicates()\n",
    "# color_repeat_count = len(df_labels) // len(color_palette) + 1\n",
    "# color_palette = color_palette * color_repeat_count\n",
    "# color_palette = color_palette[:len(df_labels)]\n",
    "df_labels = df_labels.sample(n=20)\n",
    "df_labels['color'] = color_palette\n",
    "\n",
    "df_sampled_emb = df_emb.join(df_labels.set_index('cluster_id'), on='cluster_id', rsuffix='_c', how=\"right\")\n",
    "df_sampled_emb = df_sampled_emb.reset_index()\n",
    "print(len(df_sampled_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['cls.predictions.bias', 'fit_denses.0.weight', 'cls.seq_relationship.weight', 'fit_denses.2.bias', 'fit_denses.4.bias', 'fit_denses.2.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'fit_denses.3.bias', 'cls.predictions.transform.LayerNorm.bias', 'fit_denses.0.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'fit_denses.3.weight', 'fit_denses.1.bias', 'fit_denses.1.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-3r5jcj7l:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3r5jcj7l:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-97ju0sgh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['cls.predictions.bias', 'fit_denses.0.weight', 'cls.seq_relationship.weight', 'fit_denses.2.bias', 'fit_denses.4.bias', 'fit_denses.2.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'fit_denses.3.bias', 'cls.predictions.transform.LayerNorm.bias', 'fit_denses.0.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'fit_denses.3.weight', 'fit_denses.1.bias', 'fit_denses.1.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-97ju0sgh:v0/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/sampled/frozen_no-aug_batch-pt128_sample50_wdc-computers-medium.json')\n",
    "predictor.config.unfreeze = False\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "checkpoint_model = ContrastivePretrainModel(transformer=predictor.trainer.model.transformer)\n",
    "# cursor = mplcursors.cursor(sc, hover=True)\n",
    "# cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "# checkpoint_path = checkpoint.split('/')\n",
    "# plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "# print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import seed_all\n",
    "seed_all(42)\n",
    "\n",
    "df_emb = project2d(df_sampled_emb, tokenizer=predictor.tokenizer, model=checkpoint_model, config=predictor.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "#\n",
    "# checkpoints = glob.glob(\"output/contrastive_frozen_wdc-computers-medium/pretrain/checkpoint-[0-9]*\")\n",
    "# checkpoints = sorted(checkpoints, key=lambda x: int(x.split('/')[-1].split('-')[-1]))\n",
    "#\n",
    "# config: ContrastiveClassifierConfig = load_as_object(\n",
    "#     \"configs/model_train/contrastive/frozen_no-aug_wdc-computers-medium.json\",\n",
    "#     ContrastiveClassifierConfig.parse_obj)\n",
    "# pretrained_tokenizer = AutoTokenizer.from_pretrained(config.transformer_name,\n",
    "#                                                      additional_special_tokens=('[COL]', '[VAL]'))\n",
    "#\n",
    "# figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "# if not os.path.exists(figures_dir):\n",
    "#     os.makedirs(figures_dir)\n",
    "#\n",
    "# for checkpoint in checkpoints:\n",
    "#     checkpoint_model = ContrastivePretrainModel(len_tokenizer=len(pretrained_tokenizer), model=config.transformer_name)\n",
    "#\n",
    "#     model_state = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))\n",
    "#     checkpoint_model.load_state_dict(model_state)\n",
    "#     checkpoint_model.to(torch.device('cpu'))\n",
    "#\n",
    "#\n",
    "#     df_emb = project2d(df_sampled_emb, tokenizer=pretrained_tokenizer, model=checkpoint_model)\n",
    "#     df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "#     df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "#\n",
    "#     fig, ax = plt.subplots()\n",
    "#     sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])\n",
    "#     # cursor = mplcursors.cursor(sc, hover=True)\n",
    "#     # cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "#     checkpoint_path = checkpoint.split('/')\n",
    "#     plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "#     print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "frame_paths = glob.glob(os.path.join(figures_dir, '*.png'))\n",
    "frame_paths = sorted(frame_paths, key=lambda x: int(x.split('/')[-1].split('.')[0].split('-')[-1]))\n",
    "\n",
    "frames = [Image.open(i) for i in frame_paths]\n",
    "frames[0].save(os.path.join(figures_dir, 'all.gif'), format='GIF', append_images=frames[1:], save_all=True, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-3rfzmkeh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3rfzmkeh:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-wm5888ah:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-wm5888ah:v0/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985507246376812, 0.9765100671140939\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "unfrozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/unfrozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "frozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/frozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "# unfrozen_predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "unfrozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "frozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "unfrozen_f1 = unfrozen_predictor.test(test_df)\n",
    "frozen_f1 = frozen_predictor.test(test_df)\n",
    "\n",
    "print(f\"{unfrozen_f1}, {frozen_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
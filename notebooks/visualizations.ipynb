{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.predictors.contrastive import ContrastivePretrainModel, ContrastiveClassifierConfig\n",
    "from src.utils import load_as_object\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  cluster_id  \\\n0            [COL] name [VAL] Present Organza - Lila        2829   \n1  [COL] name [VAL] Huggy Wuggy Plush Poppy Playt...        2042   \n2  [COL] name [VAL] 100 zipper bags, zipbags, zip...         210   \n3              [COL] name [VAL] USA Flag 90 x 150 cm        3466   \n4  [COL] name [VAL] Silicone Straws Multicolored ...        3011   \n5  [COL] name [VAL] Greta Gris Name tags for wate...        1919   \n6  [COL] name [VAL] Baby on board for cars car st...        1026   \n7  [COL] name [VAL] Silver 2020 Glossy Sticker | ...        3014   \n8  [COL] name [VAL] Tarot package: The soul&#39;s...         576   \n9     [COL] name [VAL] Pokemon Battle Figures 8-Pack        2712   \n\n                                   target_id source  \n0  prod_fde403a3-b2b8-4554-aa0f-fb47f3419def     #2  \n1  prod_4703594c-2560-46c8-ac44-11258cdcd6ee     #2  \n2  prod_96a0b945-d4e0-45d5-a95f-ee6e167dcbb3     #1  \n3  prod_6dad826b-7b94-4dd6-bed1-058b46c923da     #2  \n4  prod_406f78f9-f0ac-482c-845c-77256ccc75c2     #2  \n5  prod_55eba503-50f0-474f-8bfa-3819874315d1     #2  \n6  prod_326e1200-a170-4925-9bbb-cddd9c07fe6e     #2  \n7  prod_4c1ec05d-c18f-4a00-8dee-2b553cc6d7e2     #2  \n8  prod_e26d5da6-eb35-4893-9830-5e0282d7dad0     #1  \n9  prod_ce044a66-0f3a-45a8-be4b-e96c9569c59a     #2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>cluster_id</th>\n      <th>target_id</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[COL] name [VAL] Present Organza - Lila</td>\n      <td>2829</td>\n      <td>prod_fde403a3-b2b8-4554-aa0f-fb47f3419def</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COL] name [VAL] Huggy Wuggy Plush Poppy Playt...</td>\n      <td>2042</td>\n      <td>prod_4703594c-2560-46c8-ac44-11258cdcd6ee</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[COL] name [VAL] 100 zipper bags, zipbags, zip...</td>\n      <td>210</td>\n      <td>prod_96a0b945-d4e0-45d5-a95f-ee6e167dcbb3</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[COL] name [VAL] USA Flag 90 x 150 cm</td>\n      <td>3466</td>\n      <td>prod_6dad826b-7b94-4dd6-bed1-058b46c923da</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[COL] name [VAL] Silicone Straws Multicolored ...</td>\n      <td>3011</td>\n      <td>prod_406f78f9-f0ac-482c-845c-77256ccc75c2</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[COL] name [VAL] Greta Gris Name tags for wate...</td>\n      <td>1919</td>\n      <td>prod_55eba503-50f0-474f-8bfa-3819874315d1</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[COL] name [VAL] Baby on board for cars car st...</td>\n      <td>1026</td>\n      <td>prod_326e1200-a170-4925-9bbb-cddd9c07fe6e</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[COL] name [VAL] Silver 2020 Glossy Sticker | ...</td>\n      <td>3014</td>\n      <td>prod_4c1ec05d-c18f-4a00-8dee-2b553cc6d7e2</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[COL] name [VAL] Tarot package: The soul&amp;#39;s...</td>\n      <td>576</td>\n      <td>prod_e26d5da6-eb35-4893-9830-5e0282d7dad0</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[COL] name [VAL] Pokemon Battle Figures 8-Pack</td>\n      <td>2712</td>\n      <td>prod_ce044a66-0f3a-45a8-be4b-e96c9569c59a</td>\n      <td>#2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "                                                text  cluster_id  \\\n0  [COL] name [VAL] Toys 2-pack Eggs Splatball Sq...         310   \n1  [COL] name [VAL] Square beads with colored num...        3155   \n2  [COL] name [VAL] Unicorn 60 pcs child tattoos ...         585   \n3  [COL] name [VAL] Screen Protector in Premium T...        2973   \n4  [COL] name [VAL] Diamond Painting / Diy 5d Dia...        1431   \n5  [COL] name [VAL] Portable water filter cleaner...         254   \n6  [COL] name [VAL] Liltop Stress Relief Rotable ...        2250   \n7  [COL] name [VAL] Frost frozen Elsa Anna craft ...         229   \n8  [COL] name [VAL] INF All-in-one Crochet Kit (3...         150   \n9            [COL] name [VAL] HAPE Strandset 5 Parts        1941   \n\n                                   target_id source  \n0  prod_6b8d3169-4df4-4e3d-8e1b-d8d791651579     #2  \n1  prod_88d9a771-00da-44f4-93d9-305e37eae25e     #2  \n2  prod_a504f99b-6944-4d9f-9aa3-d2a54cb771a3     #1  \n3  prod_ba5389c9-78e3-4d8c-a8bb-e0d6b5b5a1a9     #2  \n4  prod_1acc8226-38ed-466d-b8ed-355881d90871     #2  \n5  prod_4269fbcc-317d-4927-8dbc-ed4b7f9a82c3     #1  \n6  prod_a3719366-7427-419e-919e-9cc0a545b827     #2  \n7  prod_9416498d-8e39-41c7-a617-222e310d33d0     #1  \n8  prod_fdab5b51-88d4-41e9-9c62-d9fe3eecc4e8     #2  \n9  prod_9670a18a-bae3-426e-b10d-767ea579ed35     #2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>cluster_id</th>\n      <th>target_id</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[COL] name [VAL] Toys 2-pack Eggs Splatball Sq...</td>\n      <td>310</td>\n      <td>prod_6b8d3169-4df4-4e3d-8e1b-d8d791651579</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COL] name [VAL] Square beads with colored num...</td>\n      <td>3155</td>\n      <td>prod_88d9a771-00da-44f4-93d9-305e37eae25e</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[COL] name [VAL] Unicorn 60 pcs child tattoos ...</td>\n      <td>585</td>\n      <td>prod_a504f99b-6944-4d9f-9aa3-d2a54cb771a3</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[COL] name [VAL] Screen Protector in Premium T...</td>\n      <td>2973</td>\n      <td>prod_ba5389c9-78e3-4d8c-a8bb-e0d6b5b5a1a9</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[COL] name [VAL] Diamond Painting / Diy 5d Dia...</td>\n      <td>1431</td>\n      <td>prod_1acc8226-38ed-466d-b8ed-355881d90871</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[COL] name [VAL] Portable water filter cleaner...</td>\n      <td>254</td>\n      <td>prod_4269fbcc-317d-4927-8dbc-ed4b7f9a82c3</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[COL] name [VAL] Liltop Stress Relief Rotable ...</td>\n      <td>2250</td>\n      <td>prod_a3719366-7427-419e-919e-9cc0a545b827</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[COL] name [VAL] Frost frozen Elsa Anna craft ...</td>\n      <td>229</td>\n      <td>prod_9416498d-8e39-41c7-a617-222e310d33d0</td>\n      <td>#1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[COL] name [VAL] INF All-in-one Crochet Kit (3...</td>\n      <td>150</td>\n      <td>prod_fdab5b51-88d4-41e9-9c62-d9fe3eecc4e8</td>\n      <td>#2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[COL] name [VAL] HAPE Strandset 5 Parts</td>\n      <td>1941</td>\n      <td>prod_9670a18a-bae3-426e-b10d-767ea579ed35</td>\n      <td>#2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'proprietary_scarce'\n",
    "\n",
    "train_offers_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/pretrain-train.csv')\n",
    "train_offers_df.head(10)\n",
    "\n",
    "valid_offers_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/pretrain-valid.csv')\n",
    "valid_offers_df.head(10)\n",
    "\n",
    "train_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/train.csv')\n",
    "valid_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/valid.csv')\n",
    "test_df = pd.read_csv(f'data/processed/contrastive/{dataset_name}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer(test_offers_df['text'].iloc[0]).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def encode_offer(value: str, tokenizer, bert, config) -> List[int]:\n",
    "    tokens = tokenizer(value, return_tensors=\"pt\", max_length=config.max_tokens, truncation=True)\n",
    "    encoding = bert(tokens['input_ids'], attention_mask=tokens['attention_mask'])\n",
    "    return encoding.last_hidden_state[0][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     test_offers_df['embedding'] = test_offers_df['text'].apply(encode_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     result = encode_offer(test_offers_df['text'].iloc[0])\n",
    "#     print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed numpy version 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'Installed numpy version {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def project2d(target: pd.DataFrame, tokenizer, model: ContrastivePretrainModel, config: ContrastiveClassifierConfig) -> pd.DataFrame:\n",
    "    df = target.copy()\n",
    "    with torch.no_grad():\n",
    "        df['embedding'] = df['text'].apply(lambda v: encode_offer(v, tokenizer, model.transformer, config))\n",
    "\n",
    "    embeddings_list = df['embedding'].tolist()\n",
    "    embeddings = np.asarray(embeddings_list, dtype='float')\n",
    "    scaler =  MinMaxScaler()\n",
    "    features = scaler.fit_transform(embeddings)\n",
    "    mapper = umap.UMAP(n_components=2, metric=\"cosine\", random_state=42).fit(features) # TODO: fit once use it for all the epochs\n",
    "\n",
    "    projection_df = pd.DataFrame(mapper.embedding_, columns=['X', 'Y'])\n",
    "    projection_df['X'] = scaler.fit_transform(projection_df[['X']])\n",
    "    projection_df['Y'] = scaler.fit_transform(projection_df[['Y']])\n",
    "    projection_df['label'] = df['cluster_id']\n",
    "    return projection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mplcursors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "from distinctipy import distinctipy\n",
    "\n",
    "df_emb = train_offers_df.copy()\n",
    "color_palette = distinctipy.get_colors(20)\n",
    "\n",
    "df_labels = df_emb.groupby('cluster_id').filter(lambda x: len(x) > 2)[['cluster_id']].drop_duplicates()\n",
    "# color_repeat_count = len(df_labels) // len(color_palette) + 1\n",
    "# color_palette = color_palette * color_repeat_count\n",
    "# color_palette = color_palette[:len(df_labels)]\n",
    "df_labels = df_labels.sample(n=20)\n",
    "df_labels['color'] = color_palette\n",
    "\n",
    "df_sampled_emb = df_emb.join(df_labels.set_index('cluster_id'), on='cluster_id', rsuffix='_c', how=\"right\")\n",
    "df_sampled_emb = df_sampled_emb.reset_index()\n",
    "print(len(df_sampled_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/vocab.txt from cache at /home/robert/.cache/huggingface/transformers/4ec675a1f3cd38f2ddbe71010ce58471a710dd0188687381cf6f06fa7860c86a.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Adding [COL] to the vocabulary\n",
      "Adding [VAL] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'fit_denses.2.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.3.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'fit_denses.1.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'fit_denses.1.bias', 'cls.predictions.transform.dense.weight', 'fit_denses.2.bias', 'fit_denses.3.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-2cga6d29:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-2cga6d29:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-2kcearur:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'fit_denses.2.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.3.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'fit_denses.1.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'fit_denses.1.bias', 'cls.predictions.transform.dense.weight', 'fit_denses.2.bias', 'fit_denses.3.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-2kcearur:v0/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/frozen_no-aug_batch-pt128_proprietary-scarce.json')\n",
    "predictor.config.unfreeze = False\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "checkpoint_model = ContrastivePretrainModel(transformer=predictor.trainer.model.transformer)\n",
    "# cursor = mplcursors.cursor(sc, hover=True)\n",
    "# cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "# checkpoint_path = checkpoint.split('/')\n",
    "# plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "# print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import seed_all\n",
    "seed_all(42)\n",
    "\n",
    "df_emb = project2d(df_sampled_emb, tokenizer=predictor.tokenizer, model=checkpoint_model, config=predictor.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9fnA8c9z7shOCBD23uBiBByAggNwolXrqtZda23t79flaKvV1tb2V1vrqLVqW20FrQPBvXCBA0RAtgyBsLLIvLm56/v74wTIuCE3cEfuzfPmlRfJuefe8xxInnzv811ijEEppVTysxIdgFJKqejQhK6UUilCE7pSSqUITehKKZUiNKErpVSKcCbqwt27dzeDBg1K1OWVUiopff7556XGmIJwjyUsoQ8aNIilS5cm6vJKKZWURGRra49pyUUppVKEJnSllEoRmtCVUipFaEJXSqkUoQldJS1jYNUq+Ogj8HgSHY1SiddmQheRJ0SkWERWtfK4iMhfRGSjiKwUkfHRD1OpprZuhSOPhGOPhTPPhB494PHHEx2VUokVSQv9n8Csgzx+OjC84eN64K+HH5ZSrTMGZs6EdevslnlVFdTWwg9+AJ9+mujolEqcNhO6MeYDoPwgp8wGnjS2T4AuItI7WgEq1dyyZbBjB4RCTY/X1cEDD4DfD4sW2ck9GExMjEolQjQmFvUFtjf6uqjh2K7mJ4rI9diteAYMGBCFS6vOqLQUHI6Wx/fV1Hv2tBO5MZCVBS+9BJMmxT9OpeItGp2iEuZY2F0zjDGPGmMKjTGFBQVhZ64mlVrzMZvNqawxvfjKTKLKvJTokDqFSZOgvr7l8fR0WLMG9u61yzDV1bB7N8yYYZdklEp10UjoRUD/Rl/3A3ZG4XU7tFrzMV9zFh4WE6KKelaxnavZa55KdGgpLz8f7rwTMjMPHEtPt1vjVpjv6GAQ5s2LW3hKJUw0Evp84IqG0S7HAZXGmBblllSzh9sx1DU5ZqhjN7djTKiVZ6lo+dnP4MUX7REuxx4Lv/oVfOtb4Vvufj+UlcU/RqXirc0auojMAaYB3UWkCLgDcAEYYx4BXgXOADYCHuCqWAXbkXhZHfZ4iCpCVOGgS5wj6nxmzLA/9nnzTXvoYk1N0/MsC6ZPj29sSiVCmwndGHNJG48b4HtRiyhJuOhHPWtbHBdcWGQnICJ16qlwwgn2CJd9NfOsLLjwQigogCuugPnzIS0NrroK7rgDMjISG7NS0ZSw5XOTXQ9+ThHXYTgwRVHIpBvfR0T/WRPBsuCVV+Cpp+DJJ8HlgmuvhTPOgFGjYM8eCATsc++/3x7WuHBhYmNWKpo08xyiPDmPoKlkD78gRA2Ci27cRA9+nujQOjWn0259X9Wo8Pfoo1BRcSCZA3i9sGSJ/TFxYvzjVCoWOmVCD5oKqlhACA85zMAtgw/pdbrKleSbKwhSgYNcbZl3UJ9+Gn7YojGwcqUmdJU6Ol0GqjZvso1LsYfPB9nNrXQ3P6Sn/PKQXk/EwknXqMaoomv0aLtWXtd0UBKWBUOGJCYmpWKhU622GDK1bOcyDB4MtRi8GLyU8hc8xl4ExBg/xeZe1pnhrDX9KDLX4jcpP6w+pV15JbjdII2mwDmd0L8/nHRSwsJSKuo6VUKv5i3C3bKhjr38G4BtXE4JvyfADoKUU8GzbGIyQVMZ52hVtHTvbi+xO3GinchdLruj9L33wk9EUipZdbKSS6CV4waDj3qznhreajZhKECQKvbyJN35fjyCVDFw5JEHaulOpz10UalU06kSejanYPC3OC5kkceF1LECwdliIRpDHSX8H3Xmc7ryHbLk+PgErNrkC4V4eXcZb5bsJcNhcV7v7kztmodIuCWG7HHpSqWqTvWG0yH59OF+hHTsya6CkEkes8nmFNwMwhB+2n6QEir5L19zNmVGl3zvCAIhw/dWfsUDW3awoqqWT/ZWc+e6rdy/eUeiQ1MqITpVQgfIl8sZxhJ6cAvd+CGDmE9f/o6IkMFE0hhKw8oGYRgMHnbzc4KmKp5hqzDeK6tgU60Xb+jAe6q6UIgXd5eyyxtmURelUlynS+gAaTKUHnIrveU3ZMkJ+9+eiwiDeIUcTkMaWvDhCC48fBbHiFU4H5dXUdd8lwvAgfBFZU2YZyiV2jplQj8Yp3RjoDzHaHaRw9mET+pBXXyrA8h3OcN2AolAnqtTdQ8pBWhCb5UlmXTn+wjNV28SHPQggwkJiUsdMLt3NxxWy1+4bks4tktuAiJSKrE0oR9ElkymJ3cipGORi0U2LgYyiJdaHUWh4qd/Rjp3jhhIpsMiy2GRYVn0THPx4FHDcYZJ9EqlOn1f2obuchP55nI8fIqDfDIo1GTegUwryOeEbnmsrfaQZlmMzM44pP+frz1eVlTW0NXt4vj8XP2FoJKSJvQIOCSPHGa0faJKCLdlcUxe22vQl/r8bK+rp39GGt3d9kimkDHctX4r75VVIIAlQrpl8fDRwxmYmR7jyJWKLk3oKuUFQoZfb9jKwtIKXJbgDxmmd+/Cz0cM5PXict4vq6B+/9BHQ10wxC1rNjOncExC41aqvTShq5T36NadvFdWgc8YfEE7cb9XVkHPrW6WVFQ3GccOYIBd9b79rXmlkoV2iqqU9+Ku0kYtcFt9yPDCrhJ8YcaxA1hIq48p1VFpC11FzZo1xTz339Xs3l1Dfn4G58wexbHH9kt0WHiC4ROzJxjitB75FG3b3SLhZzgsBmsNXSUZbaGrqFi7toQHH/iU7dur8PtDFBfX8uS/lvPBB18nOjRG52S2evybfQoYmJFORsM6uq6GTtFfjRqEpaOZVJLRFrqKiuefW43f37Ql7PMFeeH5NUydOjChQz1/NLQ/N678Cl8oRAhwAC7L4kdD+5PhcPD42JG8V1bBkr3V9ExzcVavbvRIcycsXqUOlSZ0FRW7dlWHPV5b66ey0kuXLs1n3MbP6JxMnhw/kn9vL2ZDrYcR2Zl8q18P+mfYJRWnJZxakM+pBfkJi1GpaNCErqIiOyeN8rK6sI8tX76badMObSPuaOmfkc6tIwYkNAalYk1r6CoqjjiiR6uPFRXpUsNKxYMmdAWA1xvA42m5m1OkJk7si9PZ8tvJ7XbQr68ulKVUPGjJpZOrqPDyjyeWsX59KQB9+uRw9dXj6dc/r12vM3Jkd3r2zGL37hqCDZN3ROyEftzxiR+6qFRnoC30TiwUMvzh9x+xbl0pwaAhGDRs317F73//EdXV7dvxx7KEn/xkChMm9MHptBCBMWMKuO32E0lPb20HKKVUNGkLvRNbt7aEykovoWaTagKBEB8v3s6MmcPa9XpZ2W6uu74QY/a10HUct1LxpAm9Eyst9WBMy+N+f4jdew59C7eDJfLSUg8vzVvL2nWl5Oa4mTlrOJMm9dXkr1QUaELvxPoPCF8nT0tzMHRI9Mdkl5fXcfdd71FX58cYqKzw8uS/llNcXMPZZ4+K+vWU6mwiqqGLyCwRWS8iG0XkljCP54nIAhFZISKrReSq6Ieqom3QoC4MGZKPy3Xg28DhELKy3EycFP2OzNdf+4r6+kCTdwU+X5DXXv0Kr/fQR9gopWxtJnQRcQAPAacDY4BLRKT5QtHfA9YYY44BpgF/FBGdO93BiQg/uPk4Zs4cRpcu6WRnuzlh8gB+/ouTcLsdUb/ehg2l+0fANOZ0WuzaGXmJxxCmTqSUiqjkMgnYaIzZDCAic4HZwJpG5xggR+xCaDZQDgSiHKuKAZfLwexzRzP73NExv1ZBQRY7drRcIiAQCNEl/+ArGxoMf+Ev3MM9lFDCSEZyH/dxOqfHKlylkk4kJZe+wPZGXxc1HGvsQWA0sBP4ErjZGNNizVIRuV5ElorI0pKSkkMMWSWrWacPb9HydzotRo0qID//4Gu93MM93MZtFFOMwbCOdVzABSxkYSxDViqpRJLQww0/aP6edyawHOgDjAUeFJEW0wONMY8aYwqNMYUFBQXtDlYlt6FDu3LV1ePIyXHjdjtwOi2OOaYn13+n8KDP8+PnXu7Fg6fJcQ8efsEvYhmyUkklkpJLEdC/0df9sFvijV0F/M7YA5A3isgWYBTwWVSiVCmjsLAv48f3oby8jsxMF5mZbU86KqWUQCsVvHWsi3aISiWtSFroS4DhIjK4oaPzYmB+s3O2AacAiEhPYCSwOZqBqtRhWUL37pkRJXOA7nTH2UrbYxQ63FGpfdpM6MaYAHAT8AawFnjWGLNaRG4QkRsaTrsbOEFEvgTeAX5mjCmNVdCqc3Hh4hZuIYusJsczyOA3/CZBUSnV8UQ0scgY8yrwarNjjzT6fCcwI7qhKXXArdxKDjncwz0UU8woRnEf93ESJyU6NKU6DDHh5n7HQWFhoVm6dGlCrq2UUslKRD43xoQdSaCrLSqlVIrQhK6UUilCE7pSSqUITehKKZUiNKErpVSK0ISulFIpQhO6UkqlCE3oSimVIjShK6VUitCErpRSKUITulJKpQhN6AqAcspZzWrqqEt0KEqpQ6QJvZPz4uUyLqMPfTie4ymggHu5N9FhKaUOgSb0Tu5GbuQFXqCeeqqpppZa7uIu5jI30aEppdpJE3on5sHDHObgxdvi+D3ck6ColFKHShN6J1ZBBRJ2D3DYze44R6OUOlya0DuxXvQim+wWxwVhClNifn2D4WVe5iIu4mIu5jVew5CYDVeUSgWa0DsxC4v7uZ9MMvcfc+Agm+yY79VpMFzJlVzMxTzLszzDM1zIhdzADW0/WSkVlib0Tu4SLuEVXuE0TmMIQ7iUS/mczxnN6JhedwlLeJ7nqaV2/7FaanmKp1jBipheW6lUFdEm0Sq1TWv4E09v8EbYMe8BArzBGxzDMXGNR6lUoC10lRA55ODG3eK4Cxe55CYgotRhPF5CZZUkagN4lTidKqFvpYLzmEsGvyGX3/I9XqEGX6LD6pQu4qJWR9hcwAVxjiY1hCqqqbzgNkq7zqSsz9mUj7wI34fLo36dPX7DvArDY6X233v8+oujo+g0Cb0SL5P4O/PZgJcA1fh4nC+YyVM6siIBetObZ3iGLLLIbfiTQw7P8zzd6Z7o8JJS5Vk/xvfyIvD5wR8gtLGIyjP+l+DGoqhdY7vPMKccNtZDRdD+e045FPn0Z6gj6DQJ/SlWUoOfUKPkXU+Qz9jBbObyLls0scfZ2ZxNMcXMYQ5zmUsxxcxiVqLDSkqBVZsILP/KTuaN+QJ4Hvhv1K7zbjUEml+74bhKvE7TKbqUnXjwtzgewLCADbzLFq7gGB7mzARE13lUevewaOvTVNWXcESP6RzR8xTOkDMSHVbSC27ZhTgdLZsk/gDBdV9H7TolzbN5G8dVfHWahH40PcnEFTapA9Ti51+s4FrGM57ecY6uc1hdvJD7PjqXkAnhD3l5a9PDDOt6HD+ZugCn5Up0eEnNecwwTPPWOUC6G9fk6I0YShfwhnkjmx6+O0TFWacpuVzJWNJxttINZ/MSYAHr4xZTZxIMBXjg40uoD3rwh+y1Y+oDtXxV9jEffv1kgqNLfo4BvUj75imQmd7ooIVkZ5Dx3fMieo2AMayqM8yvMLxdZSgJtMzcEzJbtgKdDcdV4nWahN6VDD7mGqYxqNWk7sIiO8xQOnX4vq5YRiDUckSRL+hJiYTuX7IGz5/m4p3zJsbjbfsJMZDz+G1k/eparEG9kG55pF10KvlL/4FVkN/mc/3G8HQ5vFMNG+phRR38pwzW1jVN6sdmwdEZdhJ3i/330Rn2cZV4nabkAjCCbrzLt9lNDUO4n7pm3TsWwkUcmaDoUpslDmil09lhJe+3oQkEqLrwdnxvLwF/ENwuam76I10WPoTz6GFxjUUcDjJ/dCmZP7q03c9d6YHywIEOT4P9+ZvVMDzd4BS7GWSJcHIuTM42VIUg14I0S+stHUVELXQRmSUi60Vko4jc0so500RkuYisFpH3oxtmdPUim6c5n0xc5OAmBzcZOHmc2fTTSS0xMbDLODKcLf9t0xxZTBt8DQB1/moWbn6c51bdwbKdLxMywbCv5fFXsbViBbW+vTGNORLex1/G99YSqPXaI0xqPJi91VR+49akmtizvr7l6BUADCyqgS/rDHWhA/eTZgkFTtFk3sG02TQSEQfwEHAaUAQsEZH5xpg1jc7pAjwMzDLGbBORHrEKOFrOZRS7+RGvsxEDzGQoeaS3+Tx1aCyx+J/Jz/PbD2ZiTIhAyIclTsb3OYvjB1xMUeVq7l44nUDIR32wlnRnNj2zh/GL6QtJd9orQoZMiLkrb+WtjQ/jtNwEQvVMGfgtrhz/YMJa+d7H5kOYEktodxnBDdtwjhyYgKjaL62VvOwHlnnAEninCmblGkZlaBLvqCL5KZgEbDTGbAYQkbnAbGBNo3MuBV4wxmwDMMYURzvQfULBEPW1QdJznIgc3jdWDmlcyBFRiky1ZUjXQh44aytLd7xETX0powpOZFD+OAAe+vRyav0V7CvLeAM17Kxax/y1v+ebR90FwOsb/sLbmx7BH/Lu71hdtO1pstxdufjo+G7IEdyyk/p5HxDcVRr+BBEIhH+H0RGNzYQiH2HHgAWBYEPj/PUqGJBmyNSWeYcUScmlL7C90ddFDccaGwHki8h7IvK5iFwR7oVE5HoRWSoiS0tKStoVaChkeOmeL7mx9/N8r+9z/GDgi3z0783teg2VeOnObKYMvIxZI27en8wrvXvYVb2B5jV2f8jLom3/2f/1qxvuwxf0NDnHF6zjrY0Px7W84fnTXMqPuJTa2/6K2VMe9hyrSzaO0YPiFtPhGuKGcZngAFwcPDFsTEyfr4pAJC30cL+Km//0OIEJwClABvCxiHxijNnQ5EnGPAo8ClBYWNiun8D5v13FK39cg89jt3qqir386wdLyMh1MeGc/u15KdXhtN7asxqlllpf+OTpC3oIGj9Oif0IpeDGImpv/xt4W1kDKCMNcVjkzr0bsZJnEJmIcGIOjM80FPlhkxfW1oc/tyO876jeEWLnx0F8VYauoy16TXDgcOu7hki+44qAxhmzH7AzzDmvG2NqjTGlwAcQvfVPg4EQr/1p7f5kvo/PE+SFu76M1mVUguSl96Bf7pgWi3W5rHSmDjrwZm9Q/oSwz++VMwKnFZ/hpvXPL4RgmJTmdOCcPoGse26g6+bncU0+Oi7xRFu2QxiVLkzICt/aM8CQtHhH1dSeZQFWPOJnz+ch9m4wbHk1yBcP+gnWJ08ndKxEktCXAMNFZLCIuIGLgfnNznkJmCoiThHJBI4F1kYryLoqPwFfKOxjZdtqwx5PJIPhryxhIH8mk98wmcf5hOgtkJSsjDEEfOHbd9877t/kpHUn3ZmNJU7SnNkMyh/HWaN+vP+cb439P9Icmcj+b1vB7cjg2+P+EofoG7RW2nFYpJ01mcybL8Lq3iV+8cRIL5fsH28O9nsoJzA5G/IciWsJB/2Gr+YFCfnZXycI+cFbbtj5aUd475BYbZZcjDEBEbkJeAO7xPaEMWa1iNzQ8Pgjxpi1IvI6sBIIAY8ZY1ZFK8jMLm7Sc5zUlLV8m9t3TF60LhM1d/EBf2ARtQ1dTIsp4hSe5COuYlwnXFbAGMMbf1nHgntXU7vXR37fTC767TiOu/DACJDeOSP485mbWLrjJco82xnStZAxBdOadHwP7TqRX52ymHlr7+HrvcvomzuG2aNvZUjXwrjdi/u8k6i9+x/gbzbIT4S0c0+MWxzxcHKuMDrDsN5r/+CPSocCV2LLGjU7DOHGQoQCUPpliP6p9V/QbpKosbKFhYVm6dKlEZ//3hMb+c+PP29SdnFnOPjxgumMnHJ4oyQ3LCrm2Z8vp2h1Jd36Z3LeL4+mcPah1eXr8FPAH/Yn830EOIsRzOeSw4o1Gb1y3xrm/frLFv93331yMuPP7pfAyA5N7b1P4bnriQOjWBwOsu75Dpk/vDixgXUCtbtDfPGQ326hN5M/wuKoq1N/TSAR+dwYE7YVkzRT9KZdPYyMXBcv3v0l5UUe+o7J46J7xkUlmf/h7IX7k03R6kr+dtVivPcXMuXyoe1+vSKqwm7cYIDl7D6sWJNRKGR4+d7VLfs/6oI8f+eKpEzoWT+7nLRzT8T34vt2y/z86TiGJd99JKPMnkJaF6Gu1DQZmmG5oO/k5OmEjpWkSegAx14wkGMviO5EjWduWx62s/WZ25ZzwmVDsNo53rY3OQQIX+8fSbdDjjNZeav91HvC1zZLvu54/R+Rco4ciPOWsKNzVRQYYyheHqLo/SD+WkOXoRYDZzjJ6CoceaWLLx/z4a8FBEJB6H+Sg64jHYkOO+GSKqE398nX6/j74tfYW1fDN46ezEXjT8TlaN8tFa2uCHu8tsKPt9pPZl77Rk9k4+Y6xvM4XzRZqjcTF3fEeSPmjiA9x0VGbvj+j94jdZkFFd7Wt4MUfRDcX1opXhGibJ2PCT90k9FNmPhTN9XbDP5aQ84AC3d29Gr75UAJMAhI8ICedkva9yh/ef8lZj58O08tfZcFqz7lpuce5tSHbsMfbN9K+137hV/305VukZ59aL/v/sRMfsixZOPGQhhMF57hAqYw4JBeL5lZlnD+ncfgzmzaenJnOPjm3WMTFJXqyAJeQ9H7waZ1cgMhHxR9YP98iwi5Ay26jXFELZl7sIfw9QEKgQLsNU+SSVIm9PLaam5/+V94/PX7ZwjW+rys2LGZ/y7/sF2v9Y1fHt0y2WQ6mHXzKCzHof3zOLD4DadQyS3UchubuZmzGHFIr5UKTr5uOFc+OJGCwVk43Rb9j+zCD549kSNO6ZXo0FQH5Ck2SJjqiQlB5ebYDeK4Fnv8dT1QA1QDPwUWxOyK0ZeUJZcPN6/C7XTiDTR9G1/r8/L88kVcOmF6xK818RsDqK308d+fL8dbHcDptph58yhm33bUYcdpIaQn5z9x1E2+dAiTLx2S6DBUEkjLE1pZaJP0brEZNlkBvICdzBvzAPcAZ8fkqtGXlNkmNz0z7Nodlghds3La/XrTrhrGid8eSl2ln/QcJw5nUr5xUSolpOUJXYZa7N0UwjSqoFouu/MzFsqwk2G41Q52xOSKsZGUmWvqkCPJcLXsrkh3urnu+EPbNd6yhKx8tyZzpTqA0Zc66TbaQhx2Indlw8hvOskdcPCfT4M9RX0VtDLWLLwB2IuSNecAprbjdRItKVvoToeDV2+4izMe+SV1/noEwRcM8Ouzvs2kgSMTHZ5S6jA50oQxl7kIeA0BL6TlgrQxhHglcB6wG3siXxfgWeCECK7nAv4A3IxdZgG7tZsF/OrQbiEhkmamaDiBYJCPNq+myuth6tAjyc/MjlJ0Sqlk4sFeNbD5HlbZwBage4Sv8wZ2zXwbdsv8l0B8NxJsW0rMFA3H6XAwbXhyrmqnlIqeebS+OcfTwA8ifJ2ZDR/JSgvGrTDGUB/wJ9W+kEp1VruBcCvU15FcnZqHK6lb6LHy3y8+4Kfzn2BnZRm56Zn89JQL+fHJ5x/2lndKqdiYip3Mmif1bGAadmfpx8B72OWXb2LX2FONJvRmXl29hGvm3E+d3x7AVFFXy6/fnIM/GOC2GbqanlId0UTsXezf4kCnZiYwFjgVu7P0bcCLPZ3/x8DrRNZhmkxSpuTy3PKPOO6+/2HIr67i+rn3s23voe1Tfcdr/96fzPfx+Or5v3efJxBupxqlVIfwHPAn7Gn7Y7E7N98G/tPwdy12Td2DPQv0fNo3tDEZpEQL/bdvPsPv3nkWj89OxE8ueYd5X37MFz95kL5dIu3ftm0pC7/ErS8YoNJbS7csXVBKKbD7mepK7GGF2X0Ey5nYkqQTuL7ho7EnsJN5c7XAMuxfAKki6Vvo1V4Pv337mf3JHCAYClFTX8cfF77Q7tcb3Sv8xhaZrjS6ZGQdcpxKpZK6csPnf/Kz7AE/Xz7u5+O7fRSvaN/CePFysGENqTbkIekT+to928MumesPBnl/48p2v95vzvw2Ga6mS+ZmutK48/Rv4bB0vWWlTMjw5d99eEoMIT8E6+2PDc8FqdnV8YoYV2NPEGouExgf51hiLekTeu/crvgCLUegCsLA/J77vw4EgyzavIYPN60Ke/4+Jw47innX/pJxfYeS7nQxuFsvHrzwRm6celZM4lcq2VRtM/g9tGjehgKw6+OO1890OTAdO6lb2Ik8G7vmnmpNtKSvoffPL2Dq0CP5YOMq6oMHEnWGy82PTj4fgEWb13DBE7+mPuBHEESEp7/9U2aMmhD2NU8eMZbPfnx/XOJXKtn4a1opVBior4pvLJFwAvOBRRwYtngRkJ/AmGIl6VvoAHOvvJUZo8eT5nSR5U6na2YOf7vo+0weMoYqr4ezH72D0toqquvrqKr3UOmt5cIn7mFXZXmiQ1cq6eQOtAiFaYhbLug6qmPO1RBgCvBz4AZSM5lDCrTQwV5O94VrfkF5bTXlnmoGde2J02G/mZq38uOwsz1DJsTcL97nf6adF+9wlUpq7hyh3xQHOxYHCTXM5BEnpOcLPcenWhEjuaREQt+na1ZOi/XQyz3V+MJsS+cN+Cmr7YDvD5VKAoNmOsgdIOxYHCRQBwVHWfQ+3oHD3TFb6J1FSiX0cKYPP9oendIsqWe50zlt5LgERaVUchMRuo1x0G2Mtsg7kpSooR/MMX2HcOHYKWS50/cfy3KnMW3YUZw49PC3mVNKqY4i5VvoAI9d8kPOGDORf3z6FoFQkMsnnsLF40/UxbaUUimlUyR0EeH8sVM4f+yURIeilFIxk/IlF6WU6iw0oSulVIrQhK6UUilCE7pSSqWIiBK6iMwSkfUislFEbjnIeRNFJCgiF0QvRKWUUpFoM6GLiAN4CDgdGANcIiJjWjnvXuCNaAeplFKqbZG00CcBG40xm40xPmAuMDvMed8HngcObe83pZRShyWShN4X2N7o66KGY/uJSF/sfVgfOdgLicj1IrJURJaWlJS0N1allFIHEUlCDzedsvnyhX8GfmaMOejq9saYR40xhcaYwoKCgkhjVEopFYFIZooWAY032uwH7Gx2TiEwt2EqfXfgDBEJGGPmRSVKpZRSbYokoS8BhovIYGAHcDFwaeMTjDGD930uIv8EXtZkrlR8mVAAxEJERyN3Vm0mdGNMQERuwh694gCeMMasFpTs4goAABaySURBVJEbGh4/aN1cKRVbpmo7wXUvQPVOsBxIr/FYI85BHO62n6xSSkSLcxljXgVebXYsbCI3xlx5+GEppSJh6soJLvsbBBu2DgoFMLuXEfRW4Bx3bWKDU3Gn782USmKh7R9BqNmOXKEAVGzBeHQkWWejCV2pJGZqdoEJtXxAHBhPafwDUgmlCV2pJCa5A0DCbANnAkhWz7DPMYE6TPVOjN8T4+hUvHWKDS6USlVW/xMI7vgYAo2mgFgupPtoJKNrk3ONCRHasACz81P7l4AJIr0LsUbMRizdGzQVaAtdqSQmaXk4Cm9Cuo0EywmuLGTAiVhHXNLi3NDW9zA7P7Nr7MF6uwN11+eEtrydgMhVLGgLXakkJ1k9cIy9ps3zzLYPIeRvejDkx2xfBENnxig6FU/aQleqswjUhT8e9GLCdayqpKMJXanOIqdv+OPZvXV2aYrQkotSKSBUsobQ1++AtxLJG4g1dEaLUS6OEecQXPZow7h1AwhYThwjzklIzCr6NKErleSCRZ9gvlqwvz5uSlYRLF+PY+IPkKwe+8+TvIE4Jt5EaMs7mJqdSFYvrMGnIjl9EhW6ijJN6EolMRMKYja+2qyz00DQT2jzGziOurzJ+ZLdG8dR34pvkCputHCmVDKrrwDCdWgaTOXWeEfTOVTtgC0Loaoo0ZG0oC10pZKZKyv81H+AtC7xjSXVBf0w70pY9wI40uyx/CPPgfOegg6ysqW20JVKYuJMR3qOBcvV9AHLhTX4lMQElareuwPWvQgBL9RX2n+vXwDv3p7oyPbThK5UkrNGfQPpeYw9U9RygzMDGX42VvfRiQ4ttSz9a8ux/IE6WPq3xMQThpZclEpyYjlxjPkmZsQ54PdAWp6uzRILvprWjxsDEm775fjSFrpSKUKc6UhGV03msdL32FaOT+wQyRw0oSulVGROfwDc2XZpC0Cc4MqGMx5q3+vUVx/YYSrKtOSilFKR6D0OblgBi/8Iu5ZBr7Fwwo+g67DInr/1Q1hwHezdZC9ffOTF9i8Dd1bUQtSErpRSkcofAme2s0UOULoe/jPL7uMAIACr5kLNbvjW61ELT0suSikVa5/cB4H6pseC9bD1AyjfFLXLaEJXSqn2qq+G9++Ch4+Av0+C5f9sfYIXQPFqMMGWxx1uqNgStbC05KKUUu0R8MLjx8HezfbnAK/eZLe2Zz8R/jn9T4CdS1p2hgbroeCIqIWmLXSllGqP1c9CxdYDyRzAXwur5kD5xvDPOe6H4MqExuvOuzLhqEshp3fUQtOErpRS7bHpTTuBNydO2L44/HNy+sC1n8GIcyAtF3L7wUl3wlmPRjU0LbkodZi8NZUEfHVk5fdEOsgEExVDeQPt2nfz8okIZB+ktd1tOFz8YkxD04Su1CHyVJYy73fXsuWLhSBCbkFfzvnJ3xh41JREh6ZiacJ18OmfmyZ0sSC9Cww+OXFxoSUXpQ6JMYanfnomm5e9SzDgI+ivZ+/OzTx967ns3fV1osNTsdRlEFw0D7J62DNHnRnQ40i48j1I8LIL2kJX6hDsXP855Ts2EQr6mxwPBnwsnf83TvvObxMUmYqLoafBj3ZByVq7czN/cKIjAjShK3VIKou3IVbLN7ihgJ+yoq8SEJGKO7GgR/SGHEZDRCUXEZklIutFZKOI3BLm8ctEZGXDx2IROSb6oSrVcfQeNo5QwN/iuDMtg4FHT01ARKpDCXjhzR/D7/Lh12nw71lQtiHml20zoYuIA3gIOB0YA1wiImOanbYFOMkYczRwNxDdsThKdTD5fQYzauq5uNIy9x+zHE7Ss/IYd/q3ExiZ6hCePR+WPGTv+Rr02UMdHzsWavbE9LKRtNAnARuNMZuNMT5gLjC78QnGmMXGmL0NX34C9ItumEp1POf+9DGmX30n+X2GkJXfg7GzruD6Rz4mPTs2e3l6ayrZ/Pm77PrqC4wxMbmGioLSdfYm0o0nHmHsr5f+NaaXjqSG3hfY3ujrIqCVld4BuAZ4LdwDInI9cD3AgAEDIgxRqY7Jcjg47vzvc9z532/X8/xeD1u/XITD6WLAUZNxOF1tPueT5x/k3cd/gcPpJhQKktu9D5f9bgFdeg081PBVrJSsAYcrzHZ1Xti5NKaXjiShh5spEbZ5ICLTsRN62IG4xphHaSjHFBYWahNDdTprPniRl35/HZblAAyWw8lFd/2XAUdNbvU5Xy//gIVP3EHA5yXgs1t95Ts38Z9bz+HGJ5brZKaOptsICAVaHnekQc/Ydi9GUnIpAvo3+rofsLP5SSJyNPAYMNsYUxad8JRKHRW7tzLv3mvwe2up91RR76mmrnovT992Hr66VvarBD6b9zD+ek+TYyYUoqpkB3s2fxnrsFV79TjS3q7Okdb0uDMNJn0vppeOJKEvAYaLyGARcQMXA/MbnyAiA4AXgMuNMbHvylUqCa18+2lCwTBLqGJYv3hBq8+rrSgJe9yyHNRV7w37mEqwSxbAMVeAMx2w7NUWr/rQXtMlhtosuRhjAiJyE/AG4ACeMMasFpEbGh5/BPgl0A14uOHtX8AYUxi7sJVKPnXVewkFWu4lGQoF8dZUtfq8UZPPYddXXxCob1qTDQb99B05IepxdlQV3goWbVtEUVUR3TK6MXnAZHpHcaXCqHJnwdmPwll/s9dJj9MM0ogmFhljXgVebXbskUafXwtcG93QlEotwybNZNkrT+D3NlupzxiGTGh9DZAJZ13DslefoLJ4u53URXC5Mzj1+ntwZ2THOOqOocxTxt8//zv+oJ8QIXbX7GZD2QYuPOJChncbnujwWidi7x8aJ7qWi1JxMmT8yQweNw1X+oFNgV3pWYw/42q69Ws9Kbkzsrnu4UWccvVdDDzmRI446Xwuu3cBE2d/Jx5hdwhvb34bX9BHiAO7AvlDfl7Z8IoO4WxEp/4rFSciwjfvfIa1H77Iyrfn4HS5GXf6VQydeFqbz3VnZHPs+Tdx7Pk3xSHSjufriq8xYQbX1fhqqPPXkenODPOszkcTulJxZDkcHDHtAkZNmc3GT1+nYvfX7Nm0kl7DdLWMg8l0ZeJtMlHnAJej7XH8nYUmdKXirKxoI//631Px1XkIBQOICEMmnMyFd8zBcuiPZDjH9zueNze9iT90YP0cp+XkiIIjWk3o9YF6Fm9fzOri1TgdTgp7FzK+z3gsSd1Kc+remVId1HN3XUrN3mJ8ddUEfHX46z1s/vxdli74e6JD67Am9JlAYZ9CnJaTNEcaTnEyNH8oZ444M+z5gVCAx5c9zuLtiymrK2NPzR7e3PQmL66N7Y5BiabNAaXiqLJ4u728brOOPH+9h89ffpxJ5343QZF1bCLCjGEzmDpwKqWeUvLS88hNy231/DXFa6j0VhJoNGPTH/KzrnQdJbUlFGQVxCPsuNMWulJxFAz4kVbe8gf99XGOJvlkuDLon9f/oMkcYMveLfhCLcf8C0JRVVGswks4TehKxVF+78Fkdune4rjTnc5Rp1ycgIhSU156Ho4w479FhBx3TgIiig9N6ErFkYjwjdv+iTsjG6c7HQB3RhZd+w3j+AtvTnB0qWNQ/iBCJtTkmCCkO9IZ0nVIgqKKPa2hKxVn/Y84npueXMWKN/5DZck2Bh41hVFTZke0jK5q256aPcxZOafFuPW89DyuOOaKlB7logldqQTIzu/J5Iv/N9FhpKS3Nr0Vtn5ujKFLemw2H+koUvdXlVKqU2qt07PaV019ILU7nrWFrpRKal+VfcWibYuoqq9icP5g0p3p1AdbJm5LrJSfVaoJXSmVtD4r+oy3N7+9fwZp5a5KHJYDpzgJmANj0J2Wk3G9xuGI0zK2TfiA54GFwADgaiBGy6JrQldKJaVAMMA7W95pshxAiBCEoGd2T0o8JTjEQdAEOaLgCGYOmxn/IKuBycAWoAZIA36HvRj5idG/nCZ0pdpgQiHE0u6mjqasLvxOlyFC1Afr+ckJP2Gvdy+5ablkuDLiHF2D+4CvgH3ritU3fFwGbCP8js2HQRO6Uq2oXLWBbU+/RP2uEhyZGfScdSK9z5yuyb2DyHJnETThtvSDvLQ83E43PbN7xjmqZuZwIJk3Vo6d6EdE93L6nalUGNVffc2mB/5F/S57P8+gp47dL79L0XOvJTgytU+2O5uh+UNbzAh1WS4mD5gc+wAi2VcjvZXjIezyS5RpQlcqjJ3z3iTk8zc5FvL5KX5nMcH6lmOcU8HuGvjlQjj93/Czt2B7ZfxjMAZWFcOnReAL3/hu4hujv8HQrnZSdzvcpDnSmDl0JkO7Do1dkIuB8dg7LOcBtwOBVs69AWi+94YFjAQGRj80LbkoFYZ3V3HY4yKCv7IaR49uAFSv38yOF9/Au7OY9N496HveDHJGxTCZxMiGMjj2MajzQ30Q3v0aHl4KH1wJ4+K0D/P6Ujh7DuysBoeAJfDPc2H2qNafk+ZM45KjLqHWV0utv5auGV1xWjFMa6uA0wBPw9dVwJ+B3cDjYc6/Dnt0ywLserkDyMYe9RID2kJXKoyMvr3CP2AM7i72Sn+Vqzbw1X2PU7N+C4HqWmo2bGHDn56g8sv1cYw0On74OlR67WQOduu4xgfffSU+1w+EYPq/YGM51PqhygcV9XDJ8/Yvm7ZkubPokdUjtskc4Le0rIl7gKeBUqAIeB3Y0PCYA3gG+Aw78c/B7gyN0e98TehKhdHnvBlY7qaTUCy3i56zTtx/fPuc+S3KMsbnZ/ucBXGLM1oWfh2+JPzZDjvZxtq7W+xfIM1jCITg78tif/2IrQTC/Xu4gW8Dw4GLgbHAqdjDFgGOxG6tn0lM6yKa0JUKI3vIAIb/z9VkDuwLloUrL4e+F8yiz7kz9p/jbegwbc67q7jJTvQhn5/yT5ez580Pqd28PeaxH4rMViZQuh12+SPWSmrD/0Lxh2BnVeyvH7Fx2K3u5mqxSyteoBKoAz4CboxfaKA1dKValTNqKGPubH1JW2dOFoGqmjDHsxGxs2Bd0W7W3fsIJhDEBAKIZZEzZhjDbroCcSRg1mIrrh8P938KdY0699IccPnRIHFI6FMGQCBMJ2iWC04fHvvrR+xW4AXsBL5PJnZ9vLbZufXAs9i1dXdcotMWulKHqtcZ08OWZXqdOR2wV/fb+OCTBGs8hLz1mECQkM9P1ZqNlLz/aSJCbtWd02DGUMhwQm6a/feUAfDnWfG5/sAu8J1CO4Hvk+GE4d3gwjHxiSEio4F3gWOxW+rdgJ8RvtUOdnkm3Dj0GNEWulKHqOeMKYTqfex+bSGEDIjQ8/ST6DljCgD1e0rx72059s/4/JS+/xk9Tj4h3iG3Ks0J8y6Gr8pgTQmM6Aaj47zt5p9mwtQB9uia6nq4+Ei4odCOrUOZBHzS7NgKYB4t6+vDgYPvlhdVHe2fSqmkISL0OecUep1xEoGqGpy52VjOAz9Sdh09fL3ChOLQ03gIhnezPxJBBM4fY3+0R0ktzFll/33yYJg2KD5loiZ+j11D92CXWpzYE4cejW8YmtCVOkyW04m7a8uNE9J7FeDIziBU3nQikrhcdDthfLzCS2kLt9hj14MGvAH486d2K3/+JeCMZ0F5KLAGeAB74tEY4IfYLfQ40hq6UjEiIgz97rew0t2Iy247WWluMgf0psepcZianuICIbjwv/a4dW9DZ26NDz7YCk+tSEBAvYDfYLfUHyLuyRy0ha5UTGUPG8hRv7+Vso+X4d9bSc7IIeQdPUoX+IqCpTvDLw9Q64d/LoerxsU/pkTThK5UlPj2VlL60VJ85RXkjh5Gl/FHYjkduHKy6DVjaqLDSzkHGx/v6KS/LyNK6CIyC7gfe3DOY8aY3zV7XBoePwO7W+BKY0xHmt+lVExVr9vEV3/+ByYYwgQClH/8BWmvLGTUbTfiSIvTIOROZnxve0JUdbO10rJccE0nbJ1DBDV0EXFgV4ROxy71XyIizfuhT8euGA0Hrgf+GuU4leqwTCjE5keeJlTvwwTsYm6o3od3VzHFb32U4OhSl8Oyh1rmuiHbDS7LTvBnjYBLjkp0dIkRSQt9ErDRGLMZQETmArOx+3T3mQ08aexxWp+ISBcR6W2M2RX1iJXqYLy7Sgh6W25KbPwByj75gt5nnZyAqDqH4/rB9v+FF9ZCqQemD4IJMdqvMxlEktD7Ao0XoCjCnifV1jl9gSYJXUSux27BM2DAgPbGqlSHJC6nvZB3GI3HpavYyE2DK8cmOoqOIZKug3BdD82/eyM5B2PMo8aYQmNMYUFBnKehKRUj6T264e6e32I2i+V2UTD9uARFpTqjSBJ6EdC/0df9gJ2HcI5SKWvYTVfgzMnCSk9D3C7E7SJv7Bi6T52Y6NBUJxLJ+8ElwHARGQzswF7t99Jm58wHbmqorx8LVGr9XHUm6b17cPQfb6dq1Xr8FVVkDxtERr9WNslQKkbaTOjGmICI3AS8gT1s8QljzGoRuaHh8UeAV7GHLG7EHrZ4VexCVqpjspwOuoztSEsDqs4moh4bY8yr2Em78bFHGn1ugO9FNzSllFLt0UnnUymlVOrRhK6UUilCE7pSSqUITehKKZUixLQywy3mFxYpAbYe4tO7A6VRDCcZ6D13DnrPncPh3PNAY0zYmZkJS+iHQ0SWGmMKEx1HPOk9dw56z51DrO5ZSy5KKZUiNKErpVSKSNaEHue9tDsEvefOQe+5c4jJPSdlDV0ppVRLydpCV0op1YwmdKWUShEdOqGLyCwRWS8iG0XkljCPi4j8peHxlSIyPhFxRlME93xZw72uFJHFInJMIuKMprbuudF5E0UkKCIXxDO+WIjknkVkmogsF5HVIvJ+vGOMtgi+t/NEZIGIrGi456RetVVEnhCRYhFZ1crj0c9fxpgO+YG9VO8mYAjgBlYAY5qdcwbwGvaOSccBnyY67jjc8wlAfsPnp3eGe2503rvYq35ekOi44/D/3AV7394BDV/3SHTccbjn24B7Gz4vAMoBd6JjP4x7PhEYD6xq5fGo56+O3ELfvzm1McYH7NucurH9m1MbYz4BuohI73gHGkVt3rMxZrExZm/Dl59g7w6VzCL5fwb4PvA8UBzP4GIkknu+FHjBGLMNwBiT7PcdyT0bIEdEBMjGTuiB+IYZPcaYD7DvoTVRz18dOaG3tvF0e89JJu29n2uwf8MnszbvWUT6AucBj5AaIvl/HgHki8h7IvK5iFwRt+hiI5J7fhAYjb195ZfAzcaYUHzCS4io56+OvCV51DanTiIR34+ITMdO6FNiGlHsRXLPfwZ+ZowJioQ7PelEcs9OYAJwCpABfCwinxhjNsQ6uBiJ5J5nAsuBk4GhwFsi8qExpirWwSVI1PNXR07onXFz6ojuR0SOBh4DTjfGlMUptliJ5J4LgbkNybw7cIaIBIwx8+ITYtRF+r1daoypBWpF5APgGCBZE3ok93wV8DtjF5g3isgWYBTwWXxCjLuo56+OXHLZvzm1iLixN6ee3+yc+cAVDb3Fx5H8m1O3ec8iMgB4Abg8iVtrjbV5z8aYwcaYQcaYQcBzwI1JnMwhsu/tl4CpIuIUkUzszdfXxjnOaIrknrdhvyNBRHoCI4HNcY0yvqKevzpsC910ws2pI7znXwLdgIcbWqwBk8Qr1UV4zyklkns2xqwVkdeBlUAIeMwYE3b4WzKI8P/5buCfIvIldjniZ8aYpF1WV0TmANOA7iJSBNwBuCB2+Uun/iulVIroyCUXpZRS7aAJXSmlUoQmdKWUShGa0JVSKkVoQldKqRShCV0ppVKEJnSllEoR/w9fz51I0piiXgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "#\n",
    "# checkpoints = glob.glob(\"output/contrastive_frozen_wdc-computers-medium/pretrain/checkpoint-[0-9]*\")\n",
    "# checkpoints = sorted(checkpoints, key=lambda x: int(x.split('/')[-1].split('-')[-1]))\n",
    "#\n",
    "# config: ContrastiveClassifierConfig = load_as_object(\n",
    "#     \"configs/model_train/contrastive/frozen_no-aug_wdc-computers-medium.json\",\n",
    "#     ContrastiveClassifierConfig.parse_obj)\n",
    "# pretrained_tokenizer = AutoTokenizer.from_pretrained(config.transformer_name,\n",
    "#                                                      additional_special_tokens=('[COL]', '[VAL]'))\n",
    "#\n",
    "# figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "# if not os.path.exists(figures_dir):\n",
    "#     os.makedirs(figures_dir)\n",
    "#\n",
    "# for checkpoint in checkpoints:\n",
    "#     checkpoint_model = ContrastivePretrainModel(len_tokenizer=len(pretrained_tokenizer), model=config.transformer_name)\n",
    "#\n",
    "#     model_state = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))\n",
    "#     checkpoint_model.load_state_dict(model_state)\n",
    "#     checkpoint_model.to(torch.device('cpu'))\n",
    "#\n",
    "#\n",
    "#     df_emb = project2d(df_sampled_emb, tokenizer=pretrained_tokenizer, model=checkpoint_model)\n",
    "#     df_colored_emb = df_emb.set_index('label').join(df_labels.set_index('cluster_id'), rsuffix='_c')\n",
    "#     df_colored_emb = df_colored_emb.reset_index().rename(columns={'index': 'label'})\n",
    "#\n",
    "#     fig, ax = plt.subplots()\n",
    "#     sc = ax.scatter(df_colored_emb['X'], df_colored_emb['Y'], c=df_colored_emb['color'])\n",
    "#     # cursor = mplcursors.cursor(sc, hover=True)\n",
    "#     # cursor.connect(\"add\", lambda sel: sel.annotation.set_text(df_colored_emb['label'].loc[sel.index]))\n",
    "#     checkpoint_path = checkpoint.split('/')\n",
    "#     plt.savefig(os.path.join(figures_dir, f'{checkpoint_path[-1]}.png'))\n",
    "#     print(f'Saved {checkpoint_path[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "figures_dir = os.path.join('output', 'figures', 'contrastive_frozen_wdc-computers-medium')\n",
    "frame_paths = glob.glob(os.path.join(figures_dir, '*.png'))\n",
    "frame_paths = sorted(frame_paths, key=lambda x: int(x.split('/')[-1].split('.')[0].split('-')[-1]))\n",
    "\n",
    "frames = [Image.open(i) for i in frame_paths]\n",
    "frames[0].save(os.path.join(figures_dir, 'all.gif'), format='GIF', append_images=frames[1:], save_all=True, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentsArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-3rfzmkeh:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-3rfzmkeh:v0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Downloading large artifact model-wm5888ah:v0, 54.78MB. 2 files... Done. 0:0:0\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/robert/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/pytorch_model.bin from cache at /home/robert/.cache/huggingface/transformers/4a4dca34df2df30c98747c12bff19ea7ee5380f4f180d8cfbbeff703c02793da.252b81fc76dfdd6968ed3f27881bcf37416e6c4ec326288155a94380bb85ed17\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertModel: ['fit_denses.1.weight', 'fit_denses.4.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.1.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from path: ./artifacts/model-wm5888ah:v0/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985507246376812, 0.9765100671140939\n"
     ]
    }
   ],
   "source": [
    "from src.predictors.contrastive import ContrastivePredictor\n",
    "from src.preprocess.configs import ExperimentsArgumentParser\n",
    "\n",
    "unfrozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/unfrozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "frozen_predictor = ContrastivePredictor(config_path='configs/model_train/contrastive/frozen_no-aug_batch-pt128_wdc-computers-medium.json')\n",
    "\n",
    "arguments = ExperimentsArgumentParser()\n",
    "arguments.parse_args(\"\")\n",
    "arguments.load_wandb_models = True\n",
    "# unfrozen_predictor.pretrain(train_offers_df, valid_offers_df, arguments=arguments, source_aware_sampling=False)\n",
    "unfrozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "frozen_predictor.train(pd.DataFrame(), pd.DataFrame(), arguments=arguments)\n",
    "\n",
    "unfrozen_f1 = unfrozen_predictor.test(test_df)\n",
    "frozen_f1 = frozen_predictor.test(test_df)\n",
    "\n",
    "print(f\"{unfrozen_f1}, {frozen_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}